{
 "metadata": {
  "name": "",
  "signature": "sha256:37369bd11af92708f10b9747a7f8b1aa806d15f5cda7c3882017721fecca7d34"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## How fast can I multiply two matrices on my Macbook Pro GPU?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the pyviennacl OpenCL python linear algebra library to find out."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyviennacl as p\n",
      "import numpy as np\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 256 = a 16x16 pixel image\n",
      "# (2 Spergel nu's) x (Spergel jmax+1=8)^2 x (Moffat jmax+1=4)^2 x (38 optical Zernike terms) = 77824 coeffs\n",
      "# 200 = rough number of LSST visits in r or i band.\n",
      "f = np.random.rand(256,77824).astype(np.float32)\n",
      "g = np.random.rand(77824, 200).astype(np.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadGPUf(f):\n",
      "    t0 = time.time()\n",
      "    a = p.Matrix(f)\n",
      "    t1 = time.time()\n",
      "    print \"Took {} seconds to load matrix into GPU RAM.\".format(t1-t0)\n",
      "    return a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = loadGPUf(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Took 6.28980708122 seconds to load matrix into GPU RAM.\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hmm... So it takes a while to load the GPU RAM."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadGPUg(g):\n",
      "    b = p.Matrix(g)\n",
      "    return b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = loadGPUg(g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Slightly smaller matrix still takes a while..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timeit c=a*b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 loops, best of 3: 22.9 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Holy crap that's fast!  I wish I knew if it was actually doing the computation or not (just caching the result maybe?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c=a*b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getresult(c):\n",
      "    return c.value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timeit getresult(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 320 \u00b5s per loop\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Retrieving the much smaller result matrix (256, 200) is still relatively slow."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timeit np.dot(f,g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 55.9 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Much faster to just use CPU, host RAM.  Maybe if there were a way to put the entire MCMC+linear modeler on the GPU...?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}